{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install gradio pymupdf pillow torch transformers sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T21:52:37.000085Z","iopub.execute_input":"2025-03-27T21:52:37.000517Z","iopub.status.idle":"2025-03-27T21:52:48.799003Z","shell.execute_reply.started":"2025-03-27T21:52:37.000482Z","shell.execute_reply":"2025-03-27T21:52:48.798168Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\nCollecting pymupdf\n  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting gradio-client==1.8.0 (from gradio)\n  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\nCollecting groovy~=0.1 (from gradio)\n  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.29.0)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.11.0a2)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\nCollecting ruff>=0.9.3 (from gradio)\n  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.8.0->gradio) (2024.12.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.8.0->gradio) (14.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.29.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\nInstalling collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, pymupdf, groovy, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\nSuccessfully installed fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 pymupdf-1.25.4 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import gradio as gr\nimport fitz  # PyMuPDF\nfrom PIL import Image\nimport io\nimport torch\nimport hashlib\nimport json\nfrom transformers import Blip2Processor, Blip2ForConditionalGeneration\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM  # Flan-T5 for Q&A\nfrom sentence_transformers import SentenceTransformer, util\nfrom transformers import AutoTokenizer, AutoModelForCausalLM  # Qwen for workflow\nfrom huggingface_hub import login\n\n# === Login and Device Setup ===\nlogin(token=\"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\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# === Load Models ===\nprocessor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\", use_fast=True)\nblip_model = Blip2ForConditionalGeneration.from_pretrained(\n    \"Salesforce/blip2-opt-2.7b\",\n    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n).to(device)\n\nqwen_model_id = \"Qwen/Qwen1.5-1.8B-Chat\"\nqwen_tokenizer = AutoTokenizer.from_pretrained(qwen_model_id, use_fast=True)\nqwen_model = AutoModelForCausalLM.from_pretrained(\n    qwen_model_id,\n    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n).to(device)\n\nembedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n# === Global State ===\nglobal_doc = []\nunique_images = {}\n\n# === PDF Content Extraction ===\ndef extract_page_content(doc, page_number, seen_hashes):\n    page = doc[page_number]\n    text = page.get_text()\n    images = []\n    for img in page.get_images(full=True):\n        xref = img[0]\n        base_image = doc.extract_image(xref)\n        image_bytes = base_image[\"image\"]\n        image_hash = hashlib.md5(image_bytes).hexdigest()\n        if image_hash in seen_hashes:\n            continue\n        seen_hashes.add(image_hash)\n        image_pil = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n        images.append(image_pil)\n    return text, images\n\n# === Image Captioning ===\ndef describe_images(image_list):\n    if not image_list:\n        return []\n    inputs = processor(images=image_list, return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        generated_ids = blip_model.generate(**inputs, max_new_tokens=50)\n        captions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n    return [cap.strip() for cap in captions]\n\n# === Qwen: Workflow Generation ===\ndef generate_workflow_qwen(full_text, full_captions):\n    prompt = f\"\"\"You are a technical documentation expert. Convert the following technical PDF content into a step-by-step workflow.\nWrite only numbered steps using concise and technical language.\n\nText:\n{full_text[:3000]}\n\nImage captions:\n{full_captions[:1000]}\n\nWorkflow:\"\"\"\n    inputs = qwen_tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n    with torch.no_grad():\n        outputs = qwen_model.generate(\n            **inputs,\n            max_new_tokens=1000,\n            do_sample=True,\n            top_p=0.9,\n            temperature=0.7\n        )\n    return qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# === Qwen: Interactive Guide Generation ===\ndef generate_interactive_guide_qwen(full_text, full_captions):\n    prompt = f\"\"\"You are a technical documentation expert. Read the following technical PDF content and generate an interactive guide in JSON format.\nReturn a valid JSON array where each element is an object with the following keys:\n  - \\\"name\\\": (string) The title of the step.\n  - \\\"type\\\": (string) One of \\\"instruction\\\", \\\"input_checkbox\\\", \\\"input_radio\\\", or \\\"input_number\\\".\n  - \\\"content\\\": (string) The main text or question for that step.\n  - \\\"options\\\": (optional, array) A list of strings for options if the type is \\\"input_checkbox\\\" or \\\"input_radio\\\".\n\nText:\n{full_text[:3000]}\n\nImage captions:\n{full_captions[:1000]}\n\"\"\"\n    inputs = qwen_tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n    with torch.no_grad():\n        outputs = qwen_model.generate(**inputs, max_new_tokens=1000, do_sample=False)\n    generated_text = qwen_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n    try:\n        return json.dumps(json.loads(generated_text), indent=2)\n    except Exception as e:\n        return f\"JSON parse error: {str(e)}\\nRaw output:\\n{generated_text}\"\n\n# === Qwen: Question Answering ===\ndef generate_answer_with_qwen(question, context):\n    prompt = f\"\"\"You are a helpful assistant. Based ONLY on the context below, answer the user's question clearly and accurately.\n\nContext:\n{context}\n\nQuestion: {question}\n\nAnswer:\"\"\"\n    inputs = qwen_tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n    with torch.no_grad():\n        outputs = qwen_model.generate(\n            **inputs,\n            max_new_tokens=400,\n            do_sample=False\n        )\n    output_text = qwen_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n    # Extract only the answer part (after 'Answer:')\n    answer_start = output_text.find(\"Answer:\")\n    if answer_start != -1:\n        return output_text[answer_start + len(\"Answer:\"):].strip()\n    return output_text\n\n# === Semantic Search + Answer ===\ndef answer_question(question):\n    if not global_doc:\n        return \"LÃ¼tfen Ã¶nce bir PDF dosyasÄ± yÃ¼kleyin.\"\n    chunks = [page[\"text\"] for page in global_doc]\n    for page in global_doc:\n        chunks.extend(page[\"image_descriptions\"])\n    q_emb = embedder.encode(question, convert_to_tensor=True)\n    doc_embs = embedder.encode(chunks, convert_to_tensor=True)\n    sims = util.cos_sim(q_emb, doc_embs)[0]\n    top_k = torch.topk(sims, k=min(5, len(sims)))\n    top_context = \"\\n\".join([chunks[i] for i in top_k.indices])\n    return generate_answer_with_qwen(question, top_context)\n\n# === Process PDF ===\ndef process_pdf(pdf_path):\n    doc = fitz.open(pdf_path)\n    global global_doc, unique_images\n    global_doc = []\n    unique_images = {}\n    full_text = \"\"\n    full_captions = \"\"\n    \n    for page_num in range(len(doc)):\n        seen_hashes = set()\n        text, images = extract_page_content(doc, page_num, seen_hashes)\n        full_text += f\"\\n\\n--- Page {page_num+1} ---\\n\\n{text}\"\n        captions = describe_images(images) if images else []\n        full_captions += f\"\\n\\n--- Page {page_num+1} ---\\n\\n\" + \"\\n\".join([f\"Page {page_num+1} Image {i+1}: {cap}\" for i, cap in enumerate(captions)])\n        global_doc.append({\"page\": page_num + 1, \"text\": text, \"image_descriptions\": captions})\n        for img in images:\n            img_byte_arr = io.BytesIO()\n            img.save(img_byte_arr, format='PNG')\n            image_bytes = img_byte_arr.getvalue()\n            image_hash = hashlib.md5(image_bytes).hexdigest()\n            unique_images[image_hash] = img\n    workflow_markdown = generate_workflow_qwen(full_text, full_captions)\n    interactive_guide_json = generate_interactive_guide_qwen(full_text, full_captions)\n    return full_text, list(unique_images.values()), full_captions, workflow_markdown, interactive_guide_json\n\n# === Gradio UI ===\nwith gr.Blocks() as demo:\n    gr.Markdown(\"## ğŸ“„ PDF Analyzer: Text + Images + Workflow + Interactive Guide + Q&A\")\n    with gr.Row():\n        pdf_input = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"])\n        process_btn = gr.Button(\"Process PDF\")\n    text_output = gr.Textbox(label=\"PDF Text\", lines=15)\n    image_output = gr.Gallery(label=\"Images\", show_label=False)\n    caption_output = gr.Textbox(label=\"Image Captions\", lines=10)\n    workflow_output = gr.Markdown(label=\"ğŸ“‹ Workflow\")\n    interactive_guide_output = gr.Textbox(label=\"Interactive Guide (JSON)\", lines=15)\n    gr.Markdown(\"## â“ Ask a Question\")\n    with gr.Row():\n        q_in = gr.Textbox(label=\"Your Question\")\n        q_out = gr.Textbox(label=\"Answer\", lines=8)\n    q_in.submit(answer_question, inputs=q_in, outputs=q_out)\n    process_btn.click(\n        fn=process_pdf,\n        inputs=pdf_input,\n        outputs=[text_output, image_output, caption_output, workflow_output, interactive_guide_output]\n    )\nprint(\"âœ… Gradio app is running...\")\ndemo.launch()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T21:53:00.656419Z","iopub.execute_input":"2025-03-27T21:53:00.656842Z","iopub.status.idle":"2025-03-27T21:55:53.520946Z","shell.execute_reply.started":"2025-03-27T21:53:00.656813Z","shell.execute_reply":"2025-03-27T21:55:53.519961Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0814be96a4ce4c118e467482a043f14c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/882 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d21234022304a38bdc38a7da40a641e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"082700386f154f9ea4700f4664242d38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10cf607c77004f158c98f7e942f4c8e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.56M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b005c31c17e4036b24bb00170fceaea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"661fa90da0ff45fab8a2f0fcb4a5c548"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/548 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ee866cf1d1444cb12947d36f26da9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"processor_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc6bd624796a40e98f59781c485cc520"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21314928629649718a70bc0018aa410e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/122k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ce3729f1c274b57b723c31b1bbaa5aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"397d7f7d520c4bc6b89340c237698842"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8793c9e2c19a4d689b96114551e2e883"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d09585227e409396e81cb2809febb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a169c38edab4066a206dab5a0e3e4ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a02b416172524f1caaa9fc332318c152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c24aae2e2fc41cfad51dcae3265d633"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd9af1a963144b8a911ab4e6f2c2604b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c97ba642febc44e18944de23e7da4d48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83f55eb2af104e3499a8c2064f0c2d36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697ea402e541449097c7c65a3c818f4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47fe949b68de4a1eb3ba1f22a0411d75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96f48bcff50141dd9491206a8f5f98d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17464a9e2fd34e0a9c3512c071bdd7d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a3fd2d5884642b08e17c4548af7257d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"521ac63f27ef4953b3e8f074b0c900b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0111110208744036a6a34ba9cf6725c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd4b5cc2536642279f0a0e2d66e4dedf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e116655327d14fe3ba944e002b7b3399"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee0fcdf94c79437fb3cc0b7d7d6afd79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9181d3795ac2430bac95e4de4db2053f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72b772a789a348f8a8769750a3b364cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8391ebe5645a41a1a3e4186e7916045e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72fb83d60238449abf4b6fd10071ba9b"}},"metadata":{}},{"name":"stdout","text":"âœ… Gradio app is running...\n* Running on local URL:  http://127.0.0.1:7860\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://5e942e400f6c29055e.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://5e942e400f6c29055e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77d2ca16819647aa9ca1069672686f20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2646c8ca80c9452d8dcc4a801f9df7de"}},"metadata":{}}],"execution_count":2}]}