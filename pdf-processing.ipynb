{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch\n!pip install gradio\n!pip install pymupdf\n!pip install markdown2\n!pip install requests\n!pip install weasyprint\n!pip install huggingface_hub\n!pip install pillow\n!pip install transformers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport gradio as gr\nimport fitz\nimport io\nimport hashlib\nimport markdown2\nimport requests\nimport os\nfrom weasyprint import HTML\nfrom huggingface_hub import login\nfrom PIL import Image\nfrom transformers import AutoProcessor, AutoModelForVisualQuestionAnswering, pipeline\n\n# === Login and Device Setup ===\nlogin(token=\"HF_TOKEN\")\n\nprocessor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\nblip_model = AutoModelForVisualQuestionAnswering.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n\n# Load FLAN-T5 model for QA\nt5_model_name = \"google/flan-t5-large\"\nt5_qa_model = pipeline(\"text2text-generation\", model=t5_model_name)\n\ndevice = \"cpu\" if torch.cuda.is_available() else \"cpu\"\nblip_model = blip_model.to(device)\n\n# Google Gemini API\nAPI_KEY = \"GEMINI_API_KEY\"\nGEMINI_MODEL = \"gemini-2.0-flash\"\nGEMINI_URL = f\"https://generativelanguage.googleapis.com/v1/models/{GEMINI_MODEL}:generateContent?key={API_KEY}\"\n\ndef answer_with_gemini(question, context):\n    headers = {\"Content-Type\": \"application/json\"}\n    payload = {\n        \"contents\": [\n            {\"parts\": [{\"text\": f\"Question: {question}\\nContext: {context}\"}]}\n        ]\n    }\n    response = requests.post(GEMINI_URL, headers=headers, json=payload)\n    if response.status_code == 200:\n        return response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n    else:\n        return f\"Hata: {response.status_code}\\n{response.text}\"\n\ndef generate_caption(image):\n    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n    out = blip_model.generate(**inputs)\n    caption = processor.decode(out[0], skip_special_tokens=True)\n    return caption\n\ndef extract_pdf_content(pdf_path):\n    doc = fitz.open(pdf_path)\n    pages_text, pages_images, image_captions = [], [], []\n    seen_hashes = set()\n    for page_num in range(len(doc)):\n        page = doc.load_page(page_num)\n        text = page.get_text(\"text\")\n        pages_text.append(text)\n        images, captions = [], []\n        for img in page.get_images(full=True):\n            xref = img[0]\n            base_image = doc.extract_image(xref)\n            image_bytes = base_image[\"image\"]\n            image_hash = hashlib.md5(image_bytes).hexdigest()\n            if image_hash not in seen_hashes:\n                seen_hashes.add(image_hash)\n                img_pil = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n                images.append(img_pil)\n                captions.append(generate_caption(img_pil))\n        pages_images.append(images)\n        image_captions.append(captions)\n    return pages_text, pages_images, image_captions\n\ndef generate_workflow(pages_text, image_captions):\n    workflow = \"## Workflow\\n\"\n    for i, text in enumerate(pages_text):\n        workflow += f\"### Step {i+1}: Text Content\\n{text.strip()}\\n\"\n        if i < len(image_captions) and image_captions[i]:\n            workflow += \"#### Image Descriptions:\\n\"\n            for j, caption in enumerate(image_captions[i], 1):\n                workflow += f\"- Image {j}: {caption}\\n\"\n        workflow += \"\\n\"\n    return workflow\n\ndef generate_ai_workflow(pages_text, image_captions):\n    prompt = f\"\"\"\nI have a PDF document. Each page has the following text and image descriptions.\n\nTexts:\n{pages_text}\n\nImage Captions:\n{image_captions}\n\nGenerate a clean, professional, and well-structured Markdown workflow.\n\"\"\"\n    return answer_with_gemini(\"Create workflow\", prompt)\n\ndef summarize_text(pages_text):\n    context = \"\\n\".join(pages_text)\n    return answer_with_gemini(\"Summarize this document\", context)\n\ndef generate_section_titles(pages_text):\n    return answer_with_gemini(\"Generate section titles for each page\", \"\\n\".join(pages_text))\n\ndef enrich_image_captions(text, caption):\n    prompt = f\"Context: {text}\\nImage Description: {caption}\\nImprove this image description using context.\"\n    return answer_with_gemini(\"Refine image caption\", prompt)\n\ndef convert_to_pdf(markdown_content, image_paths, output_file):\n    html_content = markdown2.markdown(markdown_content)\n    styled_html = f\"\"\"\n    <html><head><style>\n    body {{ font-family: Arial; margin: 20px; line-height: 1.6; }}\n    img {{ max-width: 100%; height: auto; margin: 10px 0; }}\n    </style></head><body>{html_content}</body></html>\n    \"\"\"\n    image_section = \"<h3>Images:</h3><ul>\"\n    for i, image_path in enumerate(image_paths):\n        image_tag = f'<li><img src=\"{image_path}\" alt=\"Image {i+1}\"></li>'\n        image_section += image_tag\n    image_section += \"</ul>\"\n    styled_html = styled_html.replace(\"</body>\", f\"{image_section}</body>\")\n    HTML(string=styled_html).write_pdf(output_file)\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"## PDF AI Workflow Analyzer (Gemini Destekli)\")\n    with gr.Row():\n        pdf_input = gr.File(label=\"PDF Yükle\", file_types=[\".pdf\"])\n        use_ai_workflow = gr.Checkbox(label=\"Gemini ile gelişmiş workflow üret\")\n        process_btn = gr.Button(\"PDF'yi İşle\")\n\n    text_output = gr.Markdown(label=\"PDF Metni\")\n    image_output = gr.Gallery(label=\"Görseller\")\n    caption_output = gr.Textbox(label=\"Açıklamalar\", lines=10)\n    workflow_output = gr.Markdown(label=\"Workflow\")\n    ai_summary_output = gr.Textbox(label=\"AI Özeti\", lines=5)\n    section_titles_output = gr.Textbox(label=\"Sayfa Başlıkları\", lines=5)\n    enriched_caption_output = gr.Textbox(label=\"Zenginleştirilmiş Captionlar\", lines=10)\n    download_pdf = gr.File(label=\"Workflow PDF\")\n\n    question_input = gr.Textbox(label=\"PDF hakkında soru sor\")\n    ask_btn = gr.Button(\"Soru Gönder\")\n    answer_output = gr.Textbox(label=\"Cevap\")\n\n    def display_pdf(pdf_path, use_ai):\n        pages_text, pages_images, image_captions = extract_pdf_content(pdf_path)\n        workflow = generate_ai_workflow(pages_text, image_captions) if use_ai else generate_workflow(pages_text, image_captions)\n        summary = summarize_text(pages_text)\n        titles = generate_section_titles(pages_text)\n\n        enriched = []\n        for text, captions in zip(pages_text, image_captions):\n            for caption in captions:\n                enriched.append(enrich_image_captions(text, caption))\n\n        image_paths = []\n        for page_idx, images in enumerate(pages_images):\n            for img_idx, img in enumerate(images):\n                img_path = f\"temp_image_{page_idx}_{img_idx}.png\"\n                img.save(img_path)\n                image_paths.append(img_path)\n\n        output_file = \"workflow.pdf\"\n        convert_to_pdf(workflow, image_paths, output_file)\n        for path in image_paths:\n            if os.path.exists(path):\n                os.remove(path)\n\n        return (\n            \"\\n\\n\".join(pages_text),\n            [img for page in pages_images for img in page],\n            \"\\n\".join([cap for caps in image_captions for cap in caps]),\n            workflow,\n            summary,\n            titles,\n            \"\\n\".join(enriched),\n            output_file\n        )\n\n    def handle_question(question, pdf_path):\n        pages_text, _, _ = extract_pdf_content(pdf_path)\n        context = \" \".join(pages_text)\n        return answer_with_gemini(question, context)\n\n    process_btn.click(fn=display_pdf, inputs=[pdf_input, use_ai_workflow], outputs=[\n        text_output, image_output, caption_output, workflow_output,\n        ai_summary_output, section_titles_output, enriched_caption_output,\n        download_pdf\n    ])\n\n    ask_btn.click(fn=handle_question, inputs=[question_input, pdf_input], outputs=answer_output)\n\ndemo.launch()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}